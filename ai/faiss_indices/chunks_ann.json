["1 Москва 2025Нейронные сети ЛОНГРИД НЕДЕЛЯ 6ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТСЛОЖНОСТЬ 2 Нейросеть — это архитектура машинного обучения, которая решает огромное количество задач.Несмотря на специфические особенности (нейроны, слои, обратное распространение ошибки), основные принципы её работы схожи с принципами классических моделей.Например, здесь всё так же оптимизируются параметры и используются функции потерь.Эта область больших данных стремительно развивается, поэтому важно держать руку на пульсе и хотя бы примерно представлять основы её работы.Мы расскажем, что такое нейросети, какие возможности они перед нами открывают, как их обучать, а также о каких подводных камнях стоит знать, чтобы полученный результат оправдывал ожидания.", "→ Что такое нейросеть → Метод обратного распространения ошибки → Обучение → Эвристики Что такое нейросеть НЕЙРОНЫ И ФУНКЦИЯ АКТИВАЦИИ Если кратко, нейросеть — это структура, в которой очень простые сущности — нейроны — получают сигнал, трансформируют его и отдают следующим нейронам. Те в свою очередь передают сигнал дальше и так далее по цепочке, пока последние нейроны не выдадут финальный результат.Если правильно настроить то, как нейроны трансформируют получаемый сигнал, можно добиться невероятного качества работы всей сети.Первое, что приходит в голову большинству людей при слове «нейрон», — человеческий мозг.Частицы нейросети действительно обязаны своему названию нейронам из человеческого мозга, однако эта связь условна.", "Нейрон в машинном обучении — это объект, который получает на вход набор чисел a11, a22, …, a nn, умножает каждое из них на сохранённые внутри нейрона значения w11, w22, …, w nn (вычисляя линейную комбинацию значений a11, a22, …, a nn) и прибавляет к ним свободный коэффициент b. Результат работы нейрона выглядит так: Значение нейрона Разберём, как нейроны получают данные.Каждый нейрон (кроме самых первых) получает информацию от множества других связанных с ним нейронов.Значение веса wii, на которое нейрон умножает входящие данные из i-го источника, показывает, насколько важен для нейрона этот источник.Чем больше вес, тем сильнее нейрон будет учитывать данные из этого источника.ТЕРМИН ТЕРМИНКонтекст Применение Краткий план 3 Что нейрон передаст следующим нейронам в сети?В теории он мог бы взять получившуюся линейную комбинацию и передавать её дальше.В реальности добавляется один важный шаг: линейная комбинация проходит через функцию активации.", "Она модифицирует значение нейрона, что в итоге может быть полезно для нейросети. Например, гладкая функция активации может добавить нелинейности к выходному значению нейрона.Пороговая функция, обнуляющая слишком маленькие значение, задаст необходимый минимум, который должен накопиться в нейроне для того, чтобы он пустил ненулевой сигнал дальше по сети.Если обозначить функцию активации через σ(x), выходное значение нейрона будет выглядеть так: Выход нейрона Связь нейрона и линейных моделей Если проанализировать, что делает нейрон — берёт n значений a11, …, a nn (пусть это будут признаки), считает их линейную комбинацию и выдаёт, пропуская через какую-то функцию, — мы поймём, что это обобщает целый класс линейных моделей.В случае с функцией активации, которая равна сигмоиде, мы получим логистическую регрессию.При пороговой функции мы получим линейный классификатор.В случае, если функция активации ничего не делает (идентичная функция), мы получим классическую линейную регрессию.", "Таким образом, нейрон — это обобщение целого семейства классических моделей, основанных на линейных преобразованиях признаков. СЛОИ.ПРОСТЕЙШАЯ НЕЙРОСЕТЬ Теперь, когда ты знаешь, как работает нейрон, начнём строить саму сеть.Нейронные сети принято конструировать послойно: слой состоит из нескольких нейронов, каждый из которых получает данные ото всех нейронов предыдущего слоя и отдаёт результат во все нейроны следующего слоя.Все слои, кроме первого и последнего, принято называть скрытыми слоями, а первый и последний слои — входным и выходным.До этого во всех задачах машинного обучения мы работали с признаками — набором чисел f11, f22, ..., f kk.Здесь поступим так же: во все первые нейроны сети подадим именно k значений.Нейроны будут изменять значения в соответствии с весами связей и передавать их дальше по сети, пока на последнем слое мы не получим выходные значения — ровно столько, сколько нейронов поставим на выходном слое.Рисунок 2.Слои нейронной сетиРисунок 1.", "Выход нейрона 4 Такая простейшая сеть, полностью основанная на слоях, называется полносвязной нейронной сетью. Её более классическое название — многослойный перцептрон.Первая нейросеть готова.Мы ещё не знаем, как её обучать, но уже сейчас в ней есть все параметры, настроив которые можно решить многие задачи из любых разделов науки о данных.Теорема Хорника, или Почему нейросети глубокие, а не широкие Теоретически даже не очень глубокие нейросети могут давать потрясающий результат.Теорема Хорника гласит, что любую гладкую функцию можно приблизить сколь угодно точно нейронной сетью с двумя слоями.Главное, чтобы нейросеть была достаточно велика.Зачем изучать глубокие нейронные сети с десятками слоёв, если согласно теореме нужно всего два слоя?Причины: 1.Мы не знаем, насколько широкой нужно сделать сеть, чтобы двух слоёв было достаточно.Есть примеры задач, приближение которых требует экспоненциального роста числа нейронов.2.Веса нейронов тоже могут расти экспоненциально.", "Для вычисления нейросетей на компьютере это недопустимо, потому что у любого типа чисел есть свои пределы и выход за эти пределы приведёт к погрешностям. 3.Никто не гарантирует, что двухслойная нейросеть будет обучаться быстро и эффективно.Искусство проектировать нейросетевую архитектуру состоит в том, чтобы сделать такую структуру сети, которая помогает в процессе обучения, а не мешает.На практике двухслойная нейросеть довольно неудобна.Нейросети и матричные преобразования Допустим, что в слое нейросети находятся два нейрона, и на этот слой приходят два значения: x11 и x22.Веса и сдвиг нейронов зададим так, как на рисунке 3.Тогда первый и второй нейроны выдадут (до функции активации) следующие результаты: ; .Полученный набор значений логично записать в виде одного объекта — вектора:ТЕРМИН Рисунок 3.", "Веса и сдвиг нейронов � � 5 Линейную алгебру мы вводим неспроста: если приглядеться, можно заметить, что вектор значений нейронов (всё ещё до функции активации) получается из входных значений, весов и сдвигов при помощи умножения матрицы на вектор. Единица во втором векторе вводится как фиктивная величина, на которую умножается сдвиг.Похожим образом поступают в линейной регрессии: для удобства рассматривают фиктивный признак 1, на который умножается ещё один обучаемый коэффициент.Как видишь, нейросеть можно представить в виде цепочки матричных преобразований и применений функций активации.Эта связь с линейной алгеброй позволяет использовать все знания о быстром параллельном умножении матриц, чтобы эффективно вычислять результат работы нейросети.Метод обратного распространения ошибки Следующее необходимое знание — метод обратного распространения ошибки.Благодаря нему можно подружить нейросети и все известные нам алгоритмы оптимизации, основанные на подсчёте производных.", "Это позволит нам обучать нейросети. Нейросеть — сложная функция.Параметры, которые участвовали в подсчёте формулы для одного нейрона, участвуют в формулах для следующего, создавая целый каскад из вычислений.В этом каскаде бывает сложно выяснить, как итоговая функция ошибки зависит от параметров отдельного нейрона, то есть какая у функции ошибки производная по этому параметру.Чтобы ответить на этот вопрос, представим каскад вычислений в виде графа.В случае с нейросетью это делается просто: нейроны — вершины графа, связи между ними — рёбра.Данные путешествуют по графу, над данными производятся вычисления, и в конце выдаётся ответ.Стоит запоминать граф вычислений в ходе работы нейросети.Воспользовавшись графом, мы узнаем, какие значения от каких параметров зависели.А если на каждом шаге графа вычислений мы узнаем производную, то тогда по правилу произведения можно легко найти любую частную производную функции ошибки по любому из параметров сети.", "Так мы поймём, как тот или иной параметр влияет на ответ. Производная сложной функции Есть функция f(x, y) = x22 + y, зависящая от x и y.Из курса школьной математики известно, что производная f по x (она же δf δx ) считается по правилу δf δx = 2x2−12−1 = 2x.� � = � �� � Рисунок 4.Граф нейросети 6 То есть, если мы изменим значение x, в локальной окрестности значение f будет расти вдвое быстрее, чем x.Что, если использовать значение функции f как аргумент в другой функции g(f) = f55?Значение x меняет значение f, а то в свою очередь влияет на результат g(f).Значит, есть производная функции g(f) по изначальному параметру x.Нужно её посчитать.Если в функцию g в качестве аргумента приходит результат другой функции f, функция g называется сложной.Тогда для подсчёта производной необходимо отдельно посчитать производную g по f ( δg δf ), а дальше по цепочке смотреть, как f зависит от x, и умножать полученный результат на δf δx (учитывая, что δg δf = 5f5−15−1 = 5f44).", "Теперь можно посчитать сложную производную: δg δx = δg δf × δf δx = 5f44 × 2x . Если зависимость между конечным ответом и параметром проходит через большее количество «промежуточных» функций, необходимо продолжать цепочку умножений до тех пор, пока не дойдёшь до нужного параметра.Такая процедура поиска всех частных производных функции ошибки по всем параметрам нейросети называется методом обратного распространения ошибки, или backpropagation.Обучение ОБОБЩЕНИЕ Вооружившись производной функции ошибки по всем параметрам нейросети, можно наконец применить методы оптимизации.Например, градиентный спуск (GD) и стохастический градиентный спуск (SGD).Перед тем как идти дальше, зафиксируем основные шаги обучения нейронной сети в самом простом виде.1.Объекты из обучающей выборки подаются на вход нейросети.Она пропускает данные через себя, каждый раз передавая данные из нейрона в нейрон, умножает данные на обучаемые веса нейронов и применяет функцию активации при выходе из нейрона.2.", "В процессе нейросеть запоминает все частные производные функции ошибки, то есть считает градиент. 3.Зная градиент, можно уменьшать функцию ошибки, изменяя веса нейронов, то есть обучать нейросеть.7 ФУНКЦИИ АКТИВАЦИИ Теперь рассмотрим различные функции активации, их плюсы, минусы и особенности применения.У всех функций есть два свойства: • Сильный сигнал оставляют сильным, а слабый — слабым (монотонность).• Добавляют нелинейность, позволяя модели улавливать более сложные зависимости.________________________________________________________________________________________________________________________ Сигмоида — классическая функция активации: = = У сигмоиды есть много замечательных математических свойств.Например, производная от неё выражается тоже через сигмоиды.= = = = 1 − = = Эта функция подходит нам для нейросети.У неё есть несколько дополнительных преимуществ: Сигмоида гладкая — это значит, что мы можем посчитать её производную в любой точке.", "Значения производной лежат между 0 и 1, что позволяет нам представить её результат как вероятность. У сигмоиды есть и недостатки: Чтобы посчитать её значение, нужно вычислить значение экспоненты в произвольной точке.Для компьютера это трудная задача, поэтому сигмоида замедляет работу нейросети.При очень больших или очень маленьких значениях сигмоида почти перестаёт изменяться — её производная сильно приближается к нулю.Это называется насыщением.___________________________________________________________________________________________ _____________________________ Если важно быстро вычислять функцию, а также бороться с насыщением, альтернативой сигмоиде послужит функция ReLU (рисунок 6).Чем она лучше: Очень просто считается: если значение положительно — никак не меняем его, а если отрицательно — обнуляем.Производная считается ещё проще.Не насыщается — какие бы большие значения ни подавались на вход, производная никогда не обнулится.", "Но это верно только для положительных значений, при отрицательных всё наоборот. Недостатки ReLU: Обнуляет производную при отрицательных входных значениях.Не гладкая — в нуле её производная резко увеличивается, это может привести к проблемам при обучении.Рисунок 5.Сигмоида Рисунок 6.ReLU 8 Несмотря на недостатки, ReLU остаётся одной из самых популярных функций активации, поскольку просто реализуется и решает проблему насыщения.Но, так как она решает её лишь частично, у ReLU есть некоторые модификации.________________________________________________________________________________________________________________________ Можно перестать занулять ReLU в отрицательной области и вместо этого добавить другую прямую, у которой будет наклон, близкий к нулевому, но всё-таки не нулевой.Тогда получится Leaky ReLU — попытка обойти основной недостаток ReLU в виде зануления градиента: В этой формуле α отвечает за наклон левой прямой.", "Поскольку нам нужно сохранить нелинейность и все полезные свойства ReLU, этот коэффициент должен быть маленьким, чтобы левая прямая была близка к оси x точно так же, как в ReLU. Есть ещё много других функций активации: начиная от модификаций ReLU и заканчивая гиперболическими тангенсами.Все они по-своему полезны и применяются в глубоком обучении (обучении глубоких нейросетей).Будет неверно однозначно указывать, в каких случаях лучше применять те или иные функции активации.Проектирование нейросетей — это во многом экспериментальная деятельность, в которой каждому стоит научиться самому выдвигать гипотезы и проверять их на практике.________________________________________________________________________________________________________________________ Ещё можно упомянуть функцию softmax.Она используется, чтобы нормировать набор значений.Если есть набор значений x11, x22, x33, ..., то нормированное значение xii будет равно: = .", "У softmax множество аргументов, поэтому не совсем корректно называть её функцией активации. В основном её используют как функцию, которая завершает последний слой нейросети и получает на вход результаты всех нейронов последнего слоя.Тогда ответ нейросети будет нормирован, причём, каким бы ни был изначальный набор значений, результатом этой функции станет набор значений из отрезка [0; 1] , а в сумме эти значения дадут единицу.Это позволяет превращать ответ нейросети в вероятность принадлежности к тому или иному классу.ФУНКЦИИ ОШИБКИ В качестве функций ошибок в глубоком обучении используются те же формулы, что и для классического машинного обучения.Подробнее о них можно прочитать в лонгриде, который посвящён терминам машинного обучения.ОПТИМИЗАЦИЯ Если подавать объекты в нейросеть по одному, делая градиентный спуск, нейросеть будет обучаться долго и нестабильно.", "Данных в обучающей выборке может быть очень много, а любой выброс (объект, который отличается по своей структуре от основной массы объектов) будет утягивать веса нейросети в сторону оптимального направления.Рисунок 7. Leaky ReLU 9 Вместо этого лучше каждый раз подавать нейросети небольшой набор объектов — батч.Пропустим каждый объект из батча через нейросеть, запомним градиент для каждого из элементов батча и сделаем градиентный спуск в усреднённом относительно всех элементов направлении.Теперь можно параллелизовать вычисления, запуская их по отдельности для каждого элемента батча.Такая модернизация позволит ускорить процесс обучения.У батчей есть ещё одно важное и полезное свойство.Каждый раз, когда в градиентном спуске делается шаг с использованием батчей, параметры нейросети изменяются на основе нескольких объектов, а не одного.Это позволяет направлять изменения в более объективную сторону, не отвлекаясь на каждый потенциальный выброс.", "Если же, наоборот, подавать в сеть по одному объекту за раз, а объект оказывается специфичным, параметры нейросети «затачиваются» под него и отклоняются от лучшего решения задачи. Поэтому батчи не только ускоряют обучение нейросетей, но ещё и улучшают его качество.Обучение не заканчивается, когда мы показали нейросети все объекты из выборки.В этот момент говорят, что прошла эпоха обучения — нейросеть один раз увидела все объекты обучающей выборки.За одну эпоху параметры нейросети могли настроиться недостаточно, например, из-за медленно изменяющихся параметров при маленьком learning rate в градиентном спуске.Поэтому нужно обучать нейросеть в течение множества эпох — многократно прогонять через неё всю обучающую выборку.Мы посчитали функцию ошибки и с помощью метода обратного распространения получили производную этой функции по всем параметрам нейросети.Теперь надо выбрать, как изменить эти параметры и оптимизировать нейросеть.", "За это отвечает оптимизатор — функция, которая задаёт правило изменения параметров и в идеале с каждым разом делает нейросеть всё лучше и лучше. Простейший вариант оптимизатора — градиентный спуск, который пересчитывает параметры так, чтобы функция ошибки уменьшалась сильнее всего.Для этого нужно сдвинуть параметры в сторону антиградиента функции ошибки: .где lr — learning rate, или темп обучения; pii, pi+1i+1 — значение параметров на i-м и (i+1) -м шагах; ∇L(pii) — градиент функции ошибки по параметрам на i-м шаге.Знак минуса перед вторым слагаемым означает, что параметры изменяются в направлении, противоположном градиенту, то есть в сторону антиградиента.У градиентного спуска есть один минус.Этот метод подразумевает, что мы считаем функцию ошибки по всей обучающей выборке, но на практике это долго и неоптимально.", "Поэтому гораздо чаще используется стохастический градиентный спуск, который считает функцию ошибки только на объектах текущего батча.ТЕРМИН ТЕРМИН ТЕРМИН 10 Эвристики ТРУДНОСТИ ОБУЧЕНИЯ Расскажем о проблемах и трудностях, которые могут возникнуть при обучении нейросети. Нейросеть с большим количеством слоёв — это сложная модель с большим количеством параметров.С одной стороны, это преимущество, потому что можно варьировать размер модели и подстраивать её под самую сложную задачу.С другой стороны, модель становится тяжеловесной.Чтобы обучать тяжёлые модели за адекватное время, нужны внушительные и дорогие вычислительные мощности.Поэтому нам потребуется ускорить обучение без критической потери качества.Затухание градиента — тоже проблема.При подсчёте частной производной в произведении начинают накапливаться множители меньше единицы, которые зануляют производную.Особенно часто это бывает, когда функция активации способна выдавать только значения меньшие единицы.", "Затухший градиент будет очень маленьким и не даст нейросети нормально обучаться: мы начнём сдвигаться на очень маленькие числа и топтаться на одном месте. Ещё встречаются мёртвые нейроны.Если в какой-то момент обучения (или при инициализации весов) все параметры нейрона обнулятся, проходящий через него градиент всегда будет равен нулю, и эти значения не получится оптимизировать.Чтобы таких бесполезных нейронов не было в нейросети, надо научиться как-то уменьшать их количество.Теперь вооружимся приёмами, которые помогут решить большинство возникающих проблем.ИНИЦИАЛИЗАЦИЯ ВЕСОВ Для начала определимся с тем, как правильно инициализировать веса.Если сделать все веса одинаковыми, есть риск, что изменяться в ходе обучения они тоже будут одинаково.Если же просто генерировать случайные числа под все параметры, можно столкнуться на старте с мёртвым нейроном.Надеяться на то, что он оживёт, не приходится, потому что его параметры никак не влияют на ответ, у них нулевая производная.", "Это значит, что градиентный спуск не будет менять их значение. Инициализация Хавьера — более надёжный и грамотный способ.Если в слой приходит A связей, а выходит B связей, то лучше всего брать случайное число из диапазона: .Получается, есть специальные числа (отдельные для каждого слоя), с помощью которых можно лучше инициализировать веса, чем если просто брать случайные числа.Кроме этого есть и другие способы инициализации весов.Однако инициализации Хавьера хватит, чтобы решить основные задачи глубокого обучения.11 НОРМАЛИЗАЦИЯ Представим, что у наших признаков разный масштаб, например: возраст, который исчисляется десятками, и зарплата, исчисляемая десятками тысяч.Если подавать столь различные значения в сеть, веса нейросети будут настолько же разного масштаба.Из-за этой несбалансированности веса будут давать сильно различающийся вклад в ответ и по-разному изменяться в ходе оптимизации.Чтобы этого избежать, можно выровнять данные.Это позволит сделать процедура нормализации.", "После неё данные приходят к одному масштабу, а их среднее значение становится равным нулю — это обеспечивает контролируемую область значений. В примере выше мы хотели нормализовать данные, входящие в нейросеть.Это называется input normalization.Иногда нужно привести к предсказуемому масштабу данные внутри одного батча — это batch normalization, а также одного слоя — layer normalization.12 Если кратко → Нейросеть — это структура, в которой нейроны получают сигнал, трансформируют его и отдают следующим нейронам.Сигнал проходит по цепочке, пока последние нейроны не выдадут финальный результат.→ Нейронные сети конструируют послойно.Один слой состоит из нескольких нейронов.Первый и последний слои — входной и выходной, остальные — скрытые.→ Чтобы понять, как тот или иной параметр влияет на ответ нейросети, можно воспользоваться методом обратного распространения ошибки.→ Функции активации модифицируют значение нейрона.Сигмоида — классическая функция активации.", "ReLU и её модификации — популярная альтернатива сигмоиде. → За эпоху обучения нейросеть видит все объекты обучающей выборки один раз.Чтобы лучше настроить параметры нейросети, нужно несколько раз прогнать через неё обучающую выборку.→ Оптимизатор — функция, которая задаёт правило изменения параметров и с каждым разом улучшает нейросеть.→ Помешать обучению нейросети могут мёртвые нейроны или затухание градиента.Справиться с этим можно с помощью таких приёмов, как нормализация и инициализация весов."]